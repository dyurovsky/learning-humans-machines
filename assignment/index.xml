<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Assignment details | Learning in Humans and Machines</title>
    <link>/learning-humans-machines/assignment/</link>
      <atom:link href="/learning-humans-machines/assignment/index.xml" rel="self" type="application/rss+xml" />
    <description>Assignment details</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <image>
      <url>/learning-humans-machines/img/social-image.png</url>
      <title>Assignment details</title>
      <link>/learning-humans-machines/assignment/</link>
    </image>
    
    <item>
      <title>Homework 1</title>
      <link>/learning-humans-machines/assignment/01-rescorla-wagner/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/learning-humans-machines/assignment/01-rescorla-wagner/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-rescorla-wagner-model&#34;&gt;The Rescorla-Wagner Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#simple-conditioning&#34;&gt;Simple conditioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#extinction&#34;&gt;Extinction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#blocking&#34;&gt;Blocking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conditioned-inhibition&#34;&gt;Conditioned inhibition&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;style type=&#34;text/css&#34;&gt;
h4 {
  margin-top: 10px;
  margin-bottom: 10px;
  padding-top: 10px;
  padding-bottom: 10px;
  border-color: #d45026;
  border-style: solid;
  background-color: rgba(212, 80, 38, 0.2);
  font-weight: normal;
}

&lt;/style&gt;
&lt;p&gt;&lt;strong&gt;Getting your assignment: &lt;/strong&gt; You can find template code for your submission here at this &lt;a href=&#34;https://classroom.github.com/a/03b_G9Em&#34;&gt;GitHub Classroom link&lt;/a&gt;. All of the code you write you should go in &lt;code&gt;hw1.Rmd&lt;/code&gt;, and please knit the Markdown file in your completed submission.&lt;/p&gt;
&lt;div id=&#34;the-rescorla-wagner-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Rescorla-Wagner Model&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;../../class/03-class/papers/rescorlawagner1972.pdf&#34;&gt;Rescorla-Wagner model&lt;/a&gt;, developed by Robert Rescorla and Allen Wagner in 1972, was extremely influential at the time of its publication because it was able to explain several puzzling findings in Pavlovian condition, especially the phenomenon of blocking. It has since been extended by researchers working in Reinforcement learning to account for a number of other interesting phenomena. It is also the basis of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Delta_rule&#34;&gt;delta rule&lt;/a&gt; used for training simple neural networks, as you’ll see later on the course.&lt;/p&gt;
&lt;p&gt;You’ll work with the same simplified version of the model that you saw in &lt;a href=&#34;../../class/03-class/slides/associative_learning.pdf&#34;&gt;class&lt;/a&gt;. The model describes the change in strength associated with a conditioned stimulus (&lt;span class=&#34;math inline&#34;&gt;\(\Delta V\)&lt;/span&gt;) with this equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta V = \alpha \cdot \left(\lambda - V_{total}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;problem-1-describe-in-words-what-each-symbol-in-this-equation-means-and-how-it-is-related-to-learning-1-point.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 1&lt;/strong&gt;: Describe, in words, what each symbol in this equation means and how it is related to learning (1 point).&lt;/h4&gt;
&lt;p&gt;Now let’s turn this equation into &lt;code&gt;R&lt;/code&gt; code. You’ll write a function called &lt;code&gt;rw_delta_v&lt;/code&gt; that computes &lt;span class=&#34;math inline&#34;&gt;\(\Delta V\)&lt;/span&gt; according to the Rescorla-Wagner equation. It should take all three of relevant parameters(&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(V_{total}\)&lt;/span&gt;). It should return the amount that the target weight will change.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;problem-2-write-rw_delta_v-1-point.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 2&lt;/strong&gt;: Write &lt;code&gt;rw_delta_v&lt;/code&gt; (1 point).&lt;/h4&gt;
&lt;p&gt;You’ll use the stub in the R Markdown file in the GitHub Repository that looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rw_delta_v &amp;lt;- function(Vtotal, alpha = .1, lambda = 1) {
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One thing to notice is that function parameters in &lt;code&gt;R&lt;/code&gt; can have defaults specified. If you don’t pass in a value for that parameter, it will get the default value inside the function.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-conditioning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple conditioning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/forward_conditioning.png&#34; width=&#34;60%&#34; style=&#34;display: block; margin: auto auto auto 0;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To get started, you’ll simulate of simple conditioning experiment in which someone experiences 10 trials of positive reinforcement in response to a conditioned stimulus. You’ll want to produce a plot of the strength of the conditioned stimulus over the course of these 10 trials so you can see the changes that the model predicts.&lt;/p&gt;
&lt;p&gt;There are lots of ways of setting up this experiment in &lt;code&gt;R&lt;/code&gt;, and you’re welcome to do it however you like. In case you’d like a hand to get started, he’s one strategy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Make a &lt;code&gt;tibble&lt;/code&gt; with 2 columns: &lt;code&gt;trial&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt;. The &lt;code&gt;trial&lt;/code&gt; column will have the values &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; through &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;, and the &lt;code&gt;V&lt;/code&gt; column will start as all &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;s.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write a for loop that iterates over the numbers &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; through &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;—these will index into the rows of your &lt;code&gt;tibble&lt;/code&gt;. Set the value of the &lt;code&gt;V&lt;/code&gt; column in each row to the result of calling your &lt;code&gt;rw_delta_v&lt;/code&gt; function on the value of &lt;code&gt;V&lt;/code&gt; in the previous row.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make a plot with &lt;code&gt;trial&lt;/code&gt; on the x-axis and &lt;code&gt;V&lt;/code&gt; on the y-axis. You can make one plot for all four of your simulations if you’re feeling comfortable with the &lt;code&gt;tidyverse&lt;/code&gt;, or 4 separate plots.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;problem-3-run-4-simulations-of-the-experimenttry-2-different-levels-of-alpha-and-2-different-levels-of-lambda.-what-effect-does-these-parameters-have-on-the-model-predictions-3-points.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 3&lt;/strong&gt;: Run 4 simulations of the experiment–try 2 different levels of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and 2 different levels of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;. What effect does these parameters have on the model predictions? (3 points).&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;extinction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extinction&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/extinction.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Now let’s see what happens if we take the reinforcer away. Set up a simulation where the participant is exposed to 10 trials in of positive reinforcement in response to a conditioned stimulus, and then 10 trials in which they get no reinforcement (&lt;span class=&#34;math inline&#34;&gt;\(\lambda = 0\)&lt;/span&gt;). Then make a plot of &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; over the course of the experiment.&lt;/p&gt;
&lt;div id=&#34;problem-4-try-the-same-parameter-values-that-you-used-above-in-this-new-experiment.-how-does-the-extinction-curve-depend-on-alpha-and-lambda-2-points.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 4&lt;/strong&gt;: Try the same parameter values that you used above in this new experiment. How does the extinction curve depend on &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;? (2 points).&lt;/h4&gt;
&lt;p&gt;This should be a fairly straightforward extension of the code you wrote for the last Problem. The critical thing will be to make sure that you are using the right value of the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; parameter on each trial—remember, no reinforcer should have no reward and thus &lt;span class=&#34;math inline&#34;&gt;\(\lambda = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;blocking&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Blocking&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/blocking.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Now you’re ready to test Rescorla-Wagner’s ability to account for the Blocking phenomenon. In this simulation, you’ll have two cues–&lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. For the first 10 trials, the simulated participant will be exposed to cue &lt;code&gt;x&lt;/code&gt; and be positively reinforced. Then, on the subsequent 30 trials, both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; will be present and the participant will get reinforced.&lt;/p&gt;
&lt;p&gt;One way to make this simulation work is to replace the &lt;code&gt;V&lt;/code&gt; column with two new columns: &lt;code&gt;Vx&lt;/code&gt; and &lt;code&gt;Vy&lt;/code&gt;. And then include two more columns in your tibble, &lt;code&gt;x_present&lt;/code&gt; and &lt;code&gt;y_present&lt;/code&gt;, which indicate whether each cue is present on each trial. You then want to make sure that you simulate updating the weight for all cues that are present &lt;span class=&#34;math inline&#34;&gt;\(\Delta V\)&lt;/span&gt;. And make sure that &lt;span class=&#34;math inline&#34;&gt;\(V_{total}\)&lt;/span&gt; has the right value on each trial!&lt;/p&gt;
&lt;div id=&#34;problem-5-implement-the-blocking-experiment-described-above-and-make-a-plot-of-the-weights-of-each-of-the-two-cues-over-the-course-of-the-40-trials.-you-can-pick-any-values-for-alpha-and-lambda-3-points.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 5&lt;/strong&gt;: Implement the blocking experiment described above and make a plot of the weights of each of the two cues over the course of the 40 trials. You can pick any values for &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; (3 points).&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conditioned-inhibition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conditioned inhibition&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/conditioned_inhibition.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Finally, you’re ready to simulate a phenomenon we talked about in class but that you didn’t see directly: Conditioned inhibition. The setup is similar to blocking–first one cue (&lt;code&gt;x&lt;/code&gt;) is presented and reinforced, and then &lt;code&gt;x&lt;/code&gt; and another cue &lt;code&gt;y&lt;/code&gt; appear together. But, this time their combination is &lt;strong&gt;not&lt;/strong&gt; reinforced. As a result, people (and the model) learn a negative value for &lt;code&gt;y&lt;/code&gt;. Intuitively, &lt;code&gt;y&lt;/code&gt; is the reason that &lt;code&gt;x&lt;/code&gt; appearing did not lead to a positive reinforcer.&lt;/p&gt;
&lt;div id=&#34;problem-6-implement-the-a-conditioned-inhibition-experiment-just-like-your-blocking-experiment-above-except-this-time-without-reinforcement-on-the-30-trials-with-both-stimuli.-make-a-plot-of-the-values-of-the-two-cues-over-the-course-of-the-experiment.-pick-any-values-for-alpha-and-lambda-2-points.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 6&lt;/strong&gt;: Implement the a conditioned inhibition experiment just like your blocking experiment above, except this time without reinforcement on the 30 trials with both stimuli. Make a plot of the values of the two cues over the course of the experiment. Pick any values for &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; (2 points).&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Homework 2</title>
      <link>/learning-humans-machines/assignment/02-networks/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/learning-humans-machines/assignment/02-networks/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#perceptrons&#34;&gt;Perceptrons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#multi-layer-networks&#34;&gt;Multi-layer networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-neuralnet-package&#34;&gt;Using the &lt;code&gt;neuralnet&lt;/code&gt; package&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;style type=&#34;text/css&#34;&gt;
h4 {
  margin-top: 10px;
  margin-bottom: 10px;
  padding-top: 10px;
  padding-bottom: 10px;
  border-color: #d45026;
  border-style: solid;
  background-color: rgba(212, 80, 38, 0.2);
  font-weight: normal;
}

&lt;/style&gt;
&lt;p&gt;&lt;strong&gt;Getting your assignment: &lt;/strong&gt; You can find template code for your submission here at this &lt;a href=&#34;https://classroom.github.com/a/UoRs801q&#34;&gt;GitHub Classroom link&lt;/a&gt;. All of the code you write you should go in &lt;code&gt;hw2.Rmd&lt;/code&gt;, and please knit the Markdown file in your completed submission.&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Neural networks were a revolution in the scientific study of cognitive neuroscience, spawning a large body of work investigating the computational properties of systems designed to model the operation of the brain’s basic computational units (&lt;a href=&#34;https://dyurovsky.github.io/learning-humans-machines/class/05-class/papers/rosenblatt1958.pdf&#34;&gt;Rosenblatt, 1958&lt;/a&gt;. These perceptrons varied along a number of dimensions, but all of them had the same critical flaw: they could not learn non-linear combinations of inputs, leading to their failure on even simple problems like Exclusive Or (XOR; Minsky &amp;amp; Papert, 1967).&lt;/p&gt;
&lt;p&gt;In the 1980s, work by David Rumelhart and his colleagues rekindled the field’s interest in neural networks by devising an algorithm by which these models &lt;em&gt;could&lt;/em&gt; learn non-linear combinations of input and develop genuinely interesting and surprisingly representations of their input (&lt;a href=&#34;https://dyurovsky.github.io/learning-humans-machines/class/06-class/papers/rumelhart1986.pdf&#34;&gt;Rumelhart, Hinton, &amp;amp; Williams, 1986&lt;/a&gt;). This lead to an explosion of work in artificial neural networks in the following decades, and also, following Marr’s perspective, a reconsideration of what these models were intended to describe (e.g. the neurons in the networks need not map on to neurons in the brain).&lt;/p&gt;
&lt;p&gt;In this assignment you will first implement simple one-layer perceptrons that learn with the perceptron learning rule. You’ll show that these can learn several logical functions: AND, OR, and NOT. But they cannot learn XOR.&lt;/p&gt;
&lt;p&gt;You will then build a very simple multi-layer network that uses backpropagation to learn XOR. You’ll finally use the &lt;code&gt;neuralnet&lt;/code&gt; package to solve this same problem, and then use it to build a digit classifier using a small version of the &lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;MNIST dataset&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;perceptrons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Perceptrons&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/perceptron.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Your first goal will be to train a perceptron to solve logical AND. I’ve provided a set of stub functions that scaffold one way of doing this. The idea is to approximate a sort of pseudo-object oriented structure using a named list. This is overkill for just this simple perceptron, but you’ll find that it extends easily to a backprop network.&lt;/p&gt;
&lt;p&gt;This object defined in the &lt;code&gt;perceptron&lt;/code&gt; function. A &lt;code&gt;perceptron&lt;/code&gt; is a list that has 5 elements:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;A &lt;code&gt;tibble&lt;/code&gt; of inputs&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A list of target &lt;code&gt;y&lt;/code&gt;s for those inputs&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A list of &lt;code&gt;output&lt;/code&gt;s for the last run of the network corresponding to these inputs&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A list of &lt;code&gt;activation&lt;/code&gt;s that occur after applying the &lt;code&gt;sigmoid&lt;/code&gt; function to those &lt;code&gt;output&lt;/code&gt;s&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A list of &lt;code&gt;weights&lt;/code&gt; – 3 in total. Two that connect from the input nodes (&lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;), and one that connects from a bias node (&lt;code&gt;1&lt;/code&gt;) to the output node (&lt;code&gt;y&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This list will track the state of the perceptron as it goes through the training function you write (&lt;code&gt;train_perceptron&lt;/code&gt;). You can write this function as two nested for loop, the outer one over iterations, and the inner one over examples. In each run of the inner loop, you will&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Run &lt;code&gt;perceptron_feedforward&lt;/code&gt; over the training example.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run &lt;code&gt;perceptron_feedback&lt;/code&gt; over that training example to update the weights.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In each run of the outer loop, you will run &lt;code&gt;perceptron_feedforward&lt;/code&gt; and &lt;code&gt;perceptron_feewdback&lt;/code&gt; on all of the examples, and then compute the error for that iteration and store it in the network, e.g. &lt;code&gt;perceptron$errors[iteration] &amp;lt;- sq_error(...)&lt;/code&gt;.You’ll need to make sure you define &lt;code&gt;perceptron$errors&lt;/code&gt; as a list of the right length at the start of the &lt;code&gt;train_perceptron&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;If you want to use these stubs, your plan of attack should be:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Write the helper functions &lt;code&gt;sigmoid&lt;/code&gt; and &lt;code&gt;sq_error&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make the &lt;code&gt;and_data&lt;/code&gt; tibble with columns &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;, and &lt;code&gt;y&lt;/code&gt; that corresponds to the four possible input and output combinations for AND&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write the &lt;code&gt;perceptron_feedforward&lt;/code&gt; and &lt;code&gt;perceptron_feedback&lt;/code&gt; functions&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write &lt;code&gt;train_perceptron&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run &lt;code&gt;train_perceptron&lt;/code&gt; on your AND data, and plot or otherwise summarize the change in errors over time and the final weights.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;problem-1-fill-out-the-stub-helper-functions-sigmoid-and-sq_error-1-point&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 1&lt;/strong&gt;: Fill out the stub helper functions &lt;code&gt;sigmoid&lt;/code&gt; and &lt;code&gt;sq_error&lt;/code&gt; (1 point)&lt;/h4&gt;
&lt;/div&gt;
&lt;div id=&#34;problem-2-write-code-to-train-a-perceptron-to-solve-logical-and.-you-can-use-the-stubs-provided-in-the-hw2.rmd-or-write-your-own.-train-the-perceptron-and-report-back-on-the-results.-did-the-error-in-the-network-go-down-over-the-course-of-training-what-were-the-final-weights-3-points&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 2&lt;/strong&gt;: Write code to train a perceptron to solve logical AND. You can use the stubs provided in the &lt;code&gt;hw2.Rmd&lt;/code&gt; or write your own. Train the perceptron, and report back on the results. Did the error in the network go down over the course of training? What were the final weights? (3 points)&lt;/h4&gt;
&lt;/div&gt;
&lt;div id=&#34;problem-3-use-your-functions-to-train-the-perceptron-on-or-not-x1-and-xor.-which-problems-did-it-succeed-on.-which-did-it-fail-on-what-were-the-final-weights-for-each-do-they-make-sense-2-points&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 3&lt;/strong&gt;: Use your functions to train the perceptron on OR, NOT X1, and XOR. Which problems did it succeed on. Which did it fail on? What were the final weights for each? Do they make sense? (2 points)&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;multi-layer-networks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multi-layer networks&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/multi-layer.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;If everything went right, you will have discovered in &lt;strong&gt;Problem 3&lt;/strong&gt; that perceptrons cannot learn to solve non-linear classification problems like XOR. But with a hidden layer, we can fix this problem. You can use the same strategy you used for your perceptron to implement a 2-layer backpropagation network. You might find the backprop by hand example we did helpful for reference for the weight update formulas.&lt;/p&gt;
&lt;div id=&#34;problem-4-write-code-to-train-a-2-layer-network-to-learn-xor.-you-should-have-3-hidden-layer-nodes-2-that-take-input-from-the-input-layer-and-1-bias-node.-after-training-investigate-the-hidden-layer-nodes.-what-has-the-network-learned-3-points&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 4&lt;/strong&gt;: Write code to train a 2-layer network to learn XOR. You should have 3 hidden layer nodes — 2 that take input from the input layer, and 1 bias node. After training, investigate the hidden layer nodes. What has the network learned? (3 points)&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-neuralnet-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the &lt;code&gt;neuralnet&lt;/code&gt; package&lt;/h2&gt;
&lt;p&gt;The network you implemented is likely to be pretty inefficient. In practice, most implementations of neural networks use matrix multiplication to compute weights and outputs, which drastically speeds things up. For the last two problems, you’ll be using the &lt;code&gt;neuralnet&lt;/code&gt; r package to investigate what these networks can learn in a more interesting problem.&lt;/p&gt;
&lt;p&gt;The workhorse of the package is the &lt;code&gt;neuralnet&lt;/code&gt; function which trains neural nets to solve problems. It uses formula notation just like &lt;code&gt;lm&lt;/code&gt; and other standard statistical methods in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;problem-5-use-the-provided-code-to-run-neuralnet-on-your-xor-data-and-the-plot-your-neuralnet-to-see-what-the-weights-on-each-node-are.-did-it-learn-the-same-thing-as-the-network-you-made-from-scratch&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 5&lt;/strong&gt;: Use the provided code to run &lt;code&gt;neuralnet&lt;/code&gt; on your xor data, and the &lt;code&gt;plot&lt;/code&gt; your neuralnet to see what the weights on each node are. Did it learn the same thing as the network you made from scratch?&lt;/h4&gt;
&lt;p&gt;Now that you understand how this package works, you’ll use it to solve a more interesting classification problem. You’ll be learning to classify handwritten digits from the &lt;strong&gt;MNIST&lt;/strong&gt; dataset that are a classic success story for modern neural networks. You’ll be working with just a small, scaled down subset of the real dataset — 100 examples of each of the digits 0-9. Here is the first example of each:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/learning-humans-machines/learning-humans-machines/img/assignments/mnist.png&#34; width=&#34;50%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Your goal will be to try out the &lt;code&gt;neuralnet&lt;/code&gt; package to find what kinds of network structures matter for learning to classify these digits. The representation you’ll work with is a linearized version of the digits — imagine taking all of the rows of these figures and chaining them all into one long row. This means your network won’t have any ability to use the spatial structure of the images. But even with just the pixel values, you’ll find that you can do a fair bit better than chance (&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{10}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;neuralnet&lt;/code&gt; package uses what is called a &lt;em&gt;one-hot&lt;/em&gt; encoding: The output layer will have ten nodes, each corresponding to a digit. The goal of the network when it reads say a &lt;span class=&#34;math inline&#34;&gt;\(9\)&lt;/span&gt; is for all of the output nodes except for the one corresponding to &lt;span class=&#34;math inline&#34;&gt;\(9\)&lt;/span&gt; to have no activation, and for the &lt;span class=&#34;math inline&#34;&gt;\(9\)&lt;/span&gt; node to have 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;problem-6-play-around-with-the-hidden-layer-structure-of-the-network.-you-can-specify-how-many-units-there-are.-for-instance-using-the-argument-hidden-2-makes-2-hidden-layer-nodes-plus-a-bias.-using-the-argument-hidden-c32-makes-2-hidden-layers---the-first-having-3-units-and-the-second-having-2-plus-a-bias.-if-the-number-of-units-gets-too-big-youll-find-that-the-network-crashes-or-fails-to-converge.-but-report-back-on-at-least-3-argument-values-that-successfully-ran.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Problem 6&lt;/strong&gt;: Play around with the hidden layer structure of the network. You can specify how many units there are. For instance, using the argument &lt;code&gt;hidden = 2&lt;/code&gt; makes 2 hidden layer nodes (plus a bias). using the argument &lt;code&gt;hidden = c(3,2)&lt;/code&gt; makes 2 hidden layers - the first having 3 units and the second having 2 (plus a bias). If the number of units gets too big you’ll find that the network crashes or fails to converge. But report back on at least 3 argument values that successfully ran.&lt;/h4&gt;
&lt;p&gt;You can use the provided &lt;code&gt;prediction_error&lt;/code&gt; function will compute how much error there is. Make sure you look at error both on the training set (&lt;code&gt;mnist_train&lt;/code&gt;) and on a set of examples that it hasn’t been trained on (&lt;code&gt;mnist_test&lt;/code&gt;). Is the network overfitting? What is it learning? Feel free to extend the &lt;code&gt;prediction_error&lt;/code&gt; function to compute other metrics if you think they would be interesting.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
